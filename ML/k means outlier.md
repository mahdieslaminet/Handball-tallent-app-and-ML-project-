# روش‌های شناسایی داده‌های پرت (Outlier) در الگوریتم K-Means

## ۱. مقدمه
الگوریتم K-Means یکی از پرکاربردترین روش‌های خوشه‌بندی است، اما به‌شدت نسبت به داده‌های پرت حساس می‌باشد.
وجود Outlier می‌تواند باعث جابه‌جایی مراکز خوشه و کاهش کیفیت خوشه‌بندی شود.
به همین دلیل، شناسایی داده‌های پرت در K-Means اهمیت زیادی دارد.

---

## ۲. تعریف داده پرت
داده پرت نقطه‌ای است که:
- فاصله زیادی از مرکز خوشه خود دارد
- با الگوی کلی داده‌ها هم‌خوانی ندارد
- می‌تواند ناشی از خطای اندازه‌گیری، نویز یا رفتار غیرعادی باشد

---

## ۳. استفاده از فاصله تا مرکز خوشه (Distance-based Method)

### ایده اصلی
در K-Means هر داده به نزدیک‌ترین مرکز خوشه تخصیص داده می‌شود.
فاصله زیاد از مرکز خوشه می‌تواند نشانه داده پرت باشد.

### بیان ریاضی
اگر:
- \( x_i \) یک داده
- \( \mu_k \) مرکز خوشه مربوطه

فاصله اقلیدسی برابر است با:

$$
d(x_i, \mu_k) = \|x_i - \mu_k\|
$$

داده‌هایی که فاصله آن‌ها از یک آستانه مشخص بیشتر باشد، Outlier محسوب می‌شوند.

---

## ۴. استفاده از توزیع فاصله‌ها (Statistical Threshold)

در این روش:
- فاصله تمام نقاط از مرکز خوشه محاسبه می‌شود
- میانگین و انحراف معیار فاصله‌ها به‌دست می‌آید

اگر:

$$
d(x_i, \mu_k) > \mu_d + \alpha \sigma_d
$$

آنگاه \( x_i \) یک داده پرت در نظر گرفته می‌شود.

مقدار \( \alpha \) معمولاً بین ۲ تا ۳ انتخاب می‌شود.

---

## ۵. استفاده از Sum of Squared Distances (SSD)

K-Means با کمینه‌سازی تابع زیر آموزش داده می‌شود:

$$
J = \sum_{i=1}^{n} \|x_i - \mu_{c_i}\|^2
$$

نقاطی که سهم زیادی در مقدار تابع هزینه دارند:
- تأثیر غیرعادی روی مدل می‌گذارند
- می‌توانند به‌عنوان داده پرت شناسایی شوند

---

## ۶. بررسی اندازه خوشه‌ها (Small Cluster Detection)

گاهی داده‌های پرت:
- یک خوشه بسیار کوچک یا تک‌عضوی تشکیل می‌دهند

در این حالت:
- خوشه‌هایی با تعداد اعضای بسیار کم
- به‌عنوان خوشه‌های پرت در نظر گرفته می‌شوند

این روش مخصوصاً برای داده‌های بزرگ کاربرد دارد.

---

## ۷. استفاده از Silhouette Score برای نقاط منفرد

ضریب سیلوئت برای هر داده به‌صورت زیر تعریف می‌شود:

$$
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
$$

که:
- \( a(i) \): میانگین فاصله داده با نقاط خوشه خودش
- \( b(i) \): کمترین میانگین فاصله با خوشه‌های دیگر

مقادیر نزدیک به:
- \( -1 \) → احتمال داده پرت
- \( 0 \) → مرز خوشه
- \( 1 \) → خوشه‌بندی مناسب

---

## ۸. محدودیت‌های K-Means در شناسایی Outlier

- فرض شکل کروی خوشه‌ها
- حساسیت شدید به نویز و داده‌های پرت
- نیاز به تعیین تعداد خوشه‌ها از قبل

به همین دلیل، K-Means ذاتاً الگوریتم تشخیص Outlier نیست.

---

## ۹. راهکارهای بهبود

- حذف Outlier قبل از اجرای K-Means
- استفاده از الگوریتم‌های مقاوم‌تر مانند:
  - DBSCAN
  - Isolation Forest
- استفاده از K-Medoids به‌جای K-Means

---

## ۱۰. جمع‌بندی نهایی

- فاصله از مرکز خوشه، اصلی‌ترین معیار تشخیص Outlier در K-Means است
- داده‌های پرت باعث جابه‌جایی مراکز خوشه می‌شوند
- K-Means ابزار مستقیم تشخیص Outlier ندارد
- شناسایی داده پرت معمولاً به‌صورت غیرمستقیم انجام می‌شود
